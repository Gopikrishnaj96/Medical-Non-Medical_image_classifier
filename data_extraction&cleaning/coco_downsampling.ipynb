{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96e5f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading val2017.zip...\n",
      "Extracting val2017.zip...\n",
      "✓ Completed val2017.zip\n",
      "Downloading annotations_trainval2017.zip...\n",
      "Extracting annotations_trainval2017.zip...\n",
      "✓ Completed annotations_trainval2017.zip\n",
      "✓ Images: 5000\n",
      "✓ Annotations: 36781\n",
      "✓ Categories: 80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "def download_coco_validation():\n",
    "    \"\"\"Download only COCO validation set - the smart approach\"\"\"\n",
    "    base_dir = \"./coco_validation\"\n",
    "    os.makedirs(f\"{base_dir}/images\", exist_ok=True)\n",
    "    os.makedirs(f\"{base_dir}/annotations\", exist_ok=True)\n",
    "    \n",
    "    # Only what you need - validation images and annotations\n",
    "    files_to_download = {\n",
    "        \"val2017.zip\": \"http://images.cocodataset.org/zips/val2017.zip\",\n",
    "        \"annotations_trainval2017.zip\": \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "    }\n",
    "    \n",
    "    for filename, url in files_to_download.items():\n",
    "        filepath = os.path.join(base_dir, filename)\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(url, filepath)\n",
    "            \n",
    "        print(f\"Extracting {filename}...\")\n",
    "        with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(base_dir)\n",
    "        \n",
    "        # Clean up\n",
    "        os.remove(filepath)\n",
    "        print(f\"✓ Completed {filename}\")\n",
    "    \n",
    "    return base_dir\n",
    "\n",
    "def get_validation_stats(coco_dir):\n",
    "    \"\"\"Quick stats on what you actually downloaded\"\"\"\n",
    "    annotation_file = os.path.join(coco_dir, \"annotations\", \"instances_val2017.json\")\n",
    "    \n",
    "    with open(annotation_file, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    print(f\"✓ Images: {len(coco_data['images'])}\")\n",
    "    print(f\"✓ Annotations: {len(coco_data['annotations'])}\")\n",
    "    print(f\"✓ Categories: {len(coco_data['categories'])}\")\n",
    "    \n",
    "    return coco_data\n",
    "\n",
    "# Execute\n",
    "if __name__ == \"__main__\":\n",
    "    coco_path = download_coco_validation()\n",
    "    validation_data = get_validation_stats(coco_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a615c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 images...\n",
      "Processed 1000 images...\n",
      "Processed 1500 images...\n",
      "Processed 2000 images...\n",
      "Processed 2500 images...\n",
      "Processed 3000 images...\n",
      "Processed 3500 images...\n",
      "Processed 4000 images...\n",
      "Processed 4500 images...\n",
      "Processed 5000 images...\n",
      "✓ Resized 5000 images to (224, 224) in ./coco_validation/val2017_224x224\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def resize_coco_images(input_folder, output_folder, size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Resize COCO validation images to specified dimensions\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png']\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(glob.glob(os.path.join(input_folder, ext)))\n",
    "    \n",
    "    resized_count = 0\n",
    "    \n",
    "    for image_path in image_files:\n",
    "        try:\n",
    "            filename = os.path.basename(image_path)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            \n",
    "            with Image.open(image_path) as img:\n",
    "                # Convert to RGB if necessary (handles RGBA, grayscale, etc.)\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                # Resize with high-quality resampling\n",
    "                img_resized = img.resize(size, Image.LANCZOS)\n",
    "                img_resized.save(output_path, 'JPEG', quality=95)\n",
    "                \n",
    "            resized_count += 1\n",
    "            \n",
    "            if resized_count % 500 == 0:\n",
    "                print(f\"Processed {resized_count} images...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "    \n",
    "    print(f\"✓ Resized {resized_count} images to {size} in {output_folder}\")\n",
    "\n",
    "# Usage - adjust paths to match your setup\n",
    "input_dir = \"./coco_validation/val2017\"  # Your COCO images folder\n",
    "output_dir = \"./coco_validation/val2017_224x224\"\n",
    "\n",
    "resize_coco_images(input_dir, output_dir, (224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb1cd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Selected 1000 images randomly\n",
      "✓ Train set: 800 images\n",
      "✓ Test set: 200 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def select_and_split_coco_images(source_folder, output_folder, \n",
    "                                num_samples=1000, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Select random images from COCO and split into train/test\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    train_dir = os.path.join(output_folder, \"train\")\n",
    "    test_dir = os.path.join(output_folder, \"test\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    all_images = glob.glob(os.path.join(source_folder, \"*.jpg\"))\n",
    "    \n",
    "    if len(all_images) < num_samples:\n",
    "        print(f\"Warning: Only {len(all_images)} images available, using all of them\")\n",
    "        num_samples = len(all_images)\n",
    "    \n",
    "    # Randomly sample the specified number of images\n",
    "    random.seed(random_state)\n",
    "    selected_images = random.sample(all_images, num_samples)\n",
    "    \n",
    "    # Split into train and test\n",
    "    train_files, test_files = train_test_split(\n",
    "        selected_images, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Copy files to respective directories\n",
    "    for file_path in train_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        shutil.copy2(file_path, os.path.join(train_dir, filename))\n",
    "    \n",
    "    for file_path in test_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        shutil.copy2(file_path, os.path.join(test_dir, filename))\n",
    "    \n",
    "    print(f\"✓ Selected {num_samples} images randomly\")\n",
    "    print(f\"✓ Train set: {len(train_files)} images\")\n",
    "    print(f\"✓ Test set: {len(test_files)} images\")\n",
    "    \n",
    "    return len(train_files), len(test_files)\n",
    "\n",
    "# Usage - adjust paths to your setup\n",
    "source_dir = \"./coco_validation/val2017\"  # Your COCO images\n",
    "output_dir = \"./coco_split_1000\"\n",
    "\n",
    "train_count, test_count = select_and_split_coco_images(\n",
    "    source_folder=source_dir,\n",
    "    output_folder=output_dir,\n",
    "    num_samples=1000,\n",
    "    test_size=0.2,  # 80% train, 20% test\n",
    "    random_state=42  # For reproducible results\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1491b620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Copied 800 medical images to train set\n",
      "✓ Copied 200 medical images to test set\n",
      "✓ Copied 800 non_medical images to train set\n",
      "✓ Copied 200 non_medical images to test set\n",
      "\n",
      "🎯 FINAL BINARY CLASSIFICATION DATASET:\n",
      "Training Set: 1600 images\n",
      "  - Medical: 800\n",
      "  - Non-medical: 800\n",
      "Test Set: 400 images\n",
      "  - Medical: 200\n",
      "  - Non-medical: 200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "def combine_medical_datasets(medical_base_folder, non_medical_base_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Combine your version_v3 (medical) and coco_split_1000 (non-medical) datasets\n",
    "    \"\"\"\n",
    "    # Create output structure\n",
    "    output_train_dir = os.path.join(output_folder, \"train\")\n",
    "    output_test_dir = os.path.join(output_folder, \"test\")\n",
    "    \n",
    "    # Create class subdirectories for binary classification\n",
    "    for split_dir in [output_train_dir, output_test_dir]:\n",
    "        os.makedirs(os.path.join(split_dir, \"medical\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(split_dir, \"non_medical\"), exist_ok=True)\n",
    "    \n",
    "    def copy_dataset_split(source_folder, dest_folder, label):\n",
    "        \"\"\"Copy images from source train/test to destination with labels\"\"\"\n",
    "        stats = {\"train\": 0, \"test\": 0}\n",
    "        \n",
    "        for split in [\"train\", \"test\"]:\n",
    "            source_split_path = os.path.join(source_folder, split)\n",
    "            dest_split_path = os.path.join(dest_folder, split, label)\n",
    "            \n",
    "            if os.path.exists(source_split_path):\n",
    "                # Handle both flat structure and subfolder structure\n",
    "                image_files = []\n",
    "                extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']\n",
    "                \n",
    "                # Check if images are directly in the split folder\n",
    "                for ext in extensions:\n",
    "                    image_files.extend(glob.glob(os.path.join(source_split_path, ext)))\n",
    "                \n",
    "                # If no images found, check subfolders\n",
    "                if not image_files:\n",
    "                    for subfolder in os.listdir(source_split_path):\n",
    "                        subfolder_path = os.path.join(source_split_path, subfolder)\n",
    "                        if os.path.isdir(subfolder_path):\n",
    "                            for ext in extensions:\n",
    "                                image_files.extend(glob.glob(os.path.join(subfolder_path, ext)))\n",
    "                \n",
    "                # Copy files\n",
    "                for img_path in image_files:\n",
    "                    filename = os.path.basename(img_path)\n",
    "                    # Rename to avoid conflicts\n",
    "                    new_filename = f\"{label}_{filename}\"\n",
    "                    shutil.copy2(img_path, os.path.join(dest_split_path, new_filename))\n",
    "                    stats[split] += 1\n",
    "                \n",
    "                print(f\"✓ Copied {stats[split]} {label} images to {split} set\")\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    # Process both datasets\n",
    "    medical_stats = copy_dataset_split(medical_base_folder, output_folder, \"medical\")\n",
    "    non_medical_stats = copy_dataset_split(non_medical_base_folder, output_folder, \"non_medical\")\n",
    "    \n",
    "    # Print final summary\n",
    "    total_train = medical_stats[\"train\"] + non_medical_stats[\"train\"]\n",
    "    total_test = medical_stats[\"test\"] + non_medical_stats[\"test\"]\n",
    "    \n",
    "    print(f\"\\n🎯 FINAL BINARY CLASSIFICATION DATASET:\")\n",
    "    print(f\"Training Set: {total_train} images\")\n",
    "    print(f\"  - Medical: {medical_stats['train']}\")\n",
    "    print(f\"  - Non-medical: {non_medical_stats['train']}\")\n",
    "    print(f\"Test Set: {total_test} images\") \n",
    "    print(f\"  - Medical: {medical_stats['test']}\")\n",
    "    print(f\"  - Non-medical: {non_medical_stats['test']}\")\n",
    "    \n",
    "    # Check for class imbalance\n",
    "    if medical_stats[\"train\"] > 0 and non_medical_stats[\"train\"] > 0:\n",
    "        ratio = max(medical_stats[\"train\"], non_medical_stats[\"train\"]) / min(medical_stats[\"train\"], non_medical_stats[\"train\"])\n",
    "        if ratio > 2:\n",
    "            print(f\"⚠️  WARNING: Class imbalance detected! Ratio: {ratio:.1f}:1\")\n",
    "    \n",
    "    return medical_stats, non_medical_stats\n",
    "\n",
    "# Usage - UPDATE THESE PATHS based on your structure\n",
    "medical_dataset_path = \"C:/Users/USER/Desktop/Medical&Non-Medical_image_classifier/dataset/version_v5\"  # Your medical images folder\n",
    "non_medical_dataset_path = \"C:/Users/USER/Desktop/Medical&Non-Medical_image_classifier/dataset/coco_split_1000\"  # Your COCO non-medical images\n",
    "combined_output_path = \"./binary_medical_classifier_dataset\"\n",
    "\n",
    "med_stats, non_med_stats = combine_medical_datasets(\n",
    "    medical_base_folder=medical_dataset_path,\n",
    "    non_medical_base_folder=non_medical_dataset_path, \n",
    "    output_folder=combined_output_path\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
