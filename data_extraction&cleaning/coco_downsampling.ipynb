{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96e5f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading val2017.zip...\n",
      "Extracting val2017.zip...\n",
      "‚úì Completed val2017.zip\n",
      "Downloading annotations_trainval2017.zip...\n",
      "Extracting annotations_trainval2017.zip...\n",
      "‚úì Completed annotations_trainval2017.zip\n",
      "‚úì Images: 5000\n",
      "‚úì Annotations: 36781\n",
      "‚úì Categories: 80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "def download_coco_validation():\n",
    "    \"\"\"Download only COCO validation set - the smart approach\"\"\"\n",
    "    base_dir = \"./coco_validation\"\n",
    "    os.makedirs(f\"{base_dir}/images\", exist_ok=True)\n",
    "    os.makedirs(f\"{base_dir}/annotations\", exist_ok=True)\n",
    "    \n",
    "    # Only what you need - validation images and annotations\n",
    "    files_to_download = {\n",
    "        \"val2017.zip\": \"http://images.cocodataset.org/zips/val2017.zip\",\n",
    "        \"annotations_trainval2017.zip\": \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "    }\n",
    "    \n",
    "    for filename, url in files_to_download.items():\n",
    "        filepath = os.path.join(base_dir, filename)\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(url, filepath)\n",
    "            \n",
    "        print(f\"Extracting {filename}...\")\n",
    "        with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(base_dir)\n",
    "        \n",
    "        # Clean up\n",
    "        os.remove(filepath)\n",
    "        print(f\"‚úì Completed {filename}\")\n",
    "    \n",
    "    return base_dir\n",
    "\n",
    "def get_validation_stats(coco_dir):\n",
    "    \"\"\"Quick stats on what you actually downloaded\"\"\"\n",
    "    annotation_file = os.path.join(coco_dir, \"annotations\", \"instances_val2017.json\")\n",
    "    \n",
    "    with open(annotation_file, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    print(f\"‚úì Images: {len(coco_data['images'])}\")\n",
    "    print(f\"‚úì Annotations: {len(coco_data['annotations'])}\")\n",
    "    print(f\"‚úì Categories: {len(coco_data['categories'])}\")\n",
    "    \n",
    "    return coco_data\n",
    "\n",
    "# Execute\n",
    "if __name__ == \"__main__\":\n",
    "    coco_path = download_coco_validation()\n",
    "    validation_data = get_validation_stats(coco_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a615c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 images...\n",
      "Processed 1000 images...\n",
      "Processed 1500 images...\n",
      "Processed 2000 images...\n",
      "Processed 2500 images...\n",
      "Processed 3000 images...\n",
      "Processed 3500 images...\n",
      "Processed 4000 images...\n",
      "Processed 4500 images...\n",
      "Processed 5000 images...\n",
      "‚úì Resized 5000 images to (224, 224) in ./coco_validation/val2017_224x224\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def resize_coco_images(input_folder, output_folder, size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Resize COCO validation images to specified dimensions\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png']\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(glob.glob(os.path.join(input_folder, ext)))\n",
    "    \n",
    "    resized_count = 0\n",
    "    \n",
    "    for image_path in image_files:\n",
    "        try:\n",
    "            filename = os.path.basename(image_path)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            \n",
    "            with Image.open(image_path) as img:\n",
    "                # Convert to RGB if necessary (handles RGBA, grayscale, etc.)\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                # Resize with high-quality resampling\n",
    "                img_resized = img.resize(size, Image.LANCZOS)\n",
    "                img_resized.save(output_path, 'JPEG', quality=95)\n",
    "                \n",
    "            resized_count += 1\n",
    "            \n",
    "            if resized_count % 500 == 0:\n",
    "                print(f\"Processed {resized_count} images...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "    \n",
    "    print(f\"‚úì Resized {resized_count} images to {size} in {output_folder}\")\n",
    "\n",
    "# Usage - adjust paths to match your setup\n",
    "input_dir = \"./coco_validation/val2017\"  # Your COCO images folder\n",
    "output_dir = \"./coco_validation/val2017_224x224\"\n",
    "\n",
    "resize_coco_images(input_dir, output_dir, (224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb1cd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Selected 1000 images randomly\n",
      "‚úì Train set: 800 images\n",
      "‚úì Test set: 200 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def select_and_split_coco_images(source_folder, output_folder, \n",
    "                                num_samples=1000, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Select random images from COCO and split into train/test\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    train_dir = os.path.join(output_folder, \"train\")\n",
    "    test_dir = os.path.join(output_folder, \"test\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    all_images = glob.glob(os.path.join(source_folder, \"*.jpg\"))\n",
    "    \n",
    "    if len(all_images) < num_samples:\n",
    "        print(f\"Warning: Only {len(all_images)} images available, using all of them\")\n",
    "        num_samples = len(all_images)\n",
    "    \n",
    "    # Randomly sample the specified number of images\n",
    "    random.seed(random_state)\n",
    "    selected_images = random.sample(all_images, num_samples)\n",
    "    \n",
    "    # Split into train and test\n",
    "    train_files, test_files = train_test_split(\n",
    "        selected_images, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Copy files to respective directories\n",
    "    for file_path in train_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        shutil.copy2(file_path, os.path.join(train_dir, filename))\n",
    "    \n",
    "    for file_path in test_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        shutil.copy2(file_path, os.path.join(test_dir, filename))\n",
    "    \n",
    "    print(f\"‚úì Selected {num_samples} images randomly\")\n",
    "    print(f\"‚úì Train set: {len(train_files)} images\")\n",
    "    print(f\"‚úì Test set: {len(test_files)} images\")\n",
    "    \n",
    "    return len(train_files), len(test_files)\n",
    "\n",
    "# Usage - adjust paths to your setup\n",
    "source_dir = \"./coco_validation/val2017\"  # Your COCO images\n",
    "output_dir = \"./coco_split_1000\"\n",
    "\n",
    "train_count, test_count = select_and_split_coco_images(\n",
    "    source_folder=source_dir,\n",
    "    output_folder=output_dir,\n",
    "    num_samples=1000,\n",
    "    test_size=0.2,  # 80% train, 20% test\n",
    "    random_state=42  # For reproducible results\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1491b620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Copied 800 medical images to train set\n",
      "‚úì Copied 200 medical images to test set\n",
      "‚úì Copied 800 non_medical images to train set\n",
      "‚úì Copied 200 non_medical images to test set\n",
      "\n",
      "üéØ FINAL BINARY CLASSIFICATION DATASET:\n",
      "Training Set: 1600 images\n",
      "  - Medical: 800\n",
      "  - Non-medical: 800\n",
      "Test Set: 400 images\n",
      "  - Medical: 200\n",
      "  - Non-medical: 200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "def combine_medical_datasets(medical_base_folder, non_medical_base_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Combine your version_v3 (medical) and coco_split_1000 (non-medical) datasets\n",
    "    \"\"\"\n",
    "    # Create output structure\n",
    "    output_train_dir = os.path.join(output_folder, \"train\")\n",
    "    output_test_dir = os.path.join(output_folder, \"test\")\n",
    "    \n",
    "    # Create class subdirectories for binary classification\n",
    "    for split_dir in [output_train_dir, output_test_dir]:\n",
    "        os.makedirs(os.path.join(split_dir, \"medical\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(split_dir, \"non_medical\"), exist_ok=True)\n",
    "    \n",
    "    def copy_dataset_split(source_folder, dest_folder, label):\n",
    "        \"\"\"Copy images from source train/test to destination with labels\"\"\"\n",
    "        stats = {\"train\": 0, \"test\": 0}\n",
    "        \n",
    "        for split in [\"train\", \"test\"]:\n",
    "            source_split_path = os.path.join(source_folder, split)\n",
    "            dest_split_path = os.path.join(dest_folder, split, label)\n",
    "            \n",
    "            if os.path.exists(source_split_path):\n",
    "                # Handle both flat structure and subfolder structure\n",
    "                image_files = []\n",
    "                extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']\n",
    "                \n",
    "                # Check if images are directly in the split folder\n",
    "                for ext in extensions:\n",
    "                    image_files.extend(glob.glob(os.path.join(source_split_path, ext)))\n",
    "                \n",
    "                # If no images found, check subfolders\n",
    "                if not image_files:\n",
    "                    for subfolder in os.listdir(source_split_path):\n",
    "                        subfolder_path = os.path.join(source_split_path, subfolder)\n",
    "                        if os.path.isdir(subfolder_path):\n",
    "                            for ext in extensions:\n",
    "                                image_files.extend(glob.glob(os.path.join(subfolder_path, ext)))\n",
    "                \n",
    "                # Copy files\n",
    "                for img_path in image_files:\n",
    "                    filename = os.path.basename(img_path)\n",
    "                    # Rename to avoid conflicts\n",
    "                    new_filename = f\"{label}_{filename}\"\n",
    "                    shutil.copy2(img_path, os.path.join(dest_split_path, new_filename))\n",
    "                    stats[split] += 1\n",
    "                \n",
    "                print(f\"‚úì Copied {stats[split]} {label} images to {split} set\")\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    # Process both datasets\n",
    "    medical_stats = copy_dataset_split(medical_base_folder, output_folder, \"medical\")\n",
    "    non_medical_stats = copy_dataset_split(non_medical_base_folder, output_folder, \"non_medical\")\n",
    "    \n",
    "    # Print final summary\n",
    "    total_train = medical_stats[\"train\"] + non_medical_stats[\"train\"]\n",
    "    total_test = medical_stats[\"test\"] + non_medical_stats[\"test\"]\n",
    "    \n",
    "    print(f\"\\nüéØ FINAL BINARY CLASSIFICATION DATASET:\")\n",
    "    print(f\"Training Set: {total_train} images\")\n",
    "    print(f\"  - Medical: {medical_stats['train']}\")\n",
    "    print(f\"  - Non-medical: {non_medical_stats['train']}\")\n",
    "    print(f\"Test Set: {total_test} images\") \n",
    "    print(f\"  - Medical: {medical_stats['test']}\")\n",
    "    print(f\"  - Non-medical: {non_medical_stats['test']}\")\n",
    "    \n",
    "    # Check for class imbalance\n",
    "    if medical_stats[\"train\"] > 0 and non_medical_stats[\"train\"] > 0:\n",
    "        ratio = max(medical_stats[\"train\"], non_medical_stats[\"train\"]) / min(medical_stats[\"train\"], non_medical_stats[\"train\"])\n",
    "        if ratio > 2:\n",
    "            print(f\"‚ö†Ô∏è  WARNING: Class imbalance detected! Ratio: {ratio:.1f}:1\")\n",
    "    \n",
    "    return medical_stats, non_medical_stats\n",
    "\n",
    "# Usage - UPDATE THESE PATHS based on your structure\n",
    "medical_dataset_path = \"C:/Users/USER/Desktop/Medical&Non-Medical_image_classifier/dataset/version_v5\"  # Your medical images folder\n",
    "non_medical_dataset_path = \"C:/Users/USER/Desktop/Medical&Non-Medical_image_classifier/dataset/coco_split_1000\"  # Your COCO non-medical images\n",
    "combined_output_path = \"./binary_medical_classifier_dataset\"\n",
    "\n",
    "med_stats, non_med_stats = combine_medical_datasets(\n",
    "    medical_base_folder=medical_dataset_path,\n",
    "    non_medical_base_folder=non_medical_dataset_path, \n",
    "    output_folder=combined_output_path\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
