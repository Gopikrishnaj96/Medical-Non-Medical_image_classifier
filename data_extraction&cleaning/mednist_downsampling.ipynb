{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8b29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import medmnist\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c18a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOCUSED_DATASETS_2D = [\n",
    "    'ChestMNIST',      # X-ray: 112,120 chest X-rays  \n",
    "    'PneumoniaMNIST',  # X-ray: 5,856 pediatric chest X-rays\n",
    "    'OrganaMNIST',     # CT: Axial view organ classification\n",
    "    'OrgancMNIST',     # CT: Coronal view organ classification  \n",
    "    'OrgansMNIST',     # CT: Sagittal view organ classification\n",
    "    'BreastMNIST'      # Ultrasound: 780 breast ultrasound images\n",
    "]\n",
    "\n",
    "FOCUSED_DATASETS_3D = [\n",
    "    'OrganMNIST3d',    # 3D CT: Organ classification volumes\n",
    "    'NoduleMNIST3d',   # 3D CT: Lung nodule malignancy detection  \n",
    "    'FractureMNIST3d', # 3D CT: Rib fracture classification\n",
    "    'AdrenalMNIST3d'   # 3D CT: Adrenal gland classification\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e56ed3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ PRE-LOADING NON-3D DATASETS FOR VERSION 5...\n",
      "‚ö†Ô∏è  WARNING: You're EXCLUDING valuable 3D CT data for no good reason\n",
      "   Loading chestmnist...\n",
      "   Loading pneumoniamnist...\n",
      "   Loading organamnist...\n",
      "   ‚ùå Failed to load organamnist: Unable to allocate 1.62 GiB for an array with shape (1734132736,) and data type uint8\n",
      "   Loading organcmnist...\n",
      "   Loading organsmnist...\n",
      "   ‚ùå Failed to load organsmnist: Unable to allocate 667. MiB for an array with shape (699052032,) and data type uint8\n",
      "   Loading breastmnist...\n",
      "‚úÖ Loaded 4 NON-3D datasets (threw away 4 valuable 3D datasets)\n",
      "\n",
      "============================================================\n",
      "üéØ CREATING VERSION V5 (NO-3D MICRO-DATASET)\n",
      "üìä Train: 800 | Test: 200\n",
      "‚ùå EXCLUDED: organmnist3d, nodulemnist3d, fracturemnist3d, adrenalmnist3d\n",
      "‚ö†Ô∏è  WARNING: You're making your dataset LESS diverse, not better\n",
      "============================================================\n",
      "\n",
      "üìÇ chestmnist: 300 train, 75 test\n",
      "   ‚úÖ Split: 300 train, 75 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17024\\3305063561.py:163: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  pil_img = Image.fromarray(img.astype(np.uint8), mode='L')\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17024\\3305063561.py:177: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  pil_img = Image.fromarray(img.astype(np.uint8), mode='L')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ pneumoniamnist: 100 train, 25 test\n",
      "   ‚úÖ Split: 100 train, 25 test\n",
      "\n",
      "üìÇ organcmnist: 100 train, 25 test\n",
      "   ‚úÖ Split: 100 train, 25 test\n",
      "\n",
      "üìÇ breastmnist: 100 train, 25 test\n",
      "   ‚úÖ Split: 100 train, 25 test\n",
      "\n",
      "‚úÖ VERSION V5 COMPLETE:\n",
      "   üìà Train_v5: 600 images\n",
      "   üß™ Test_v5: 150 images\n",
      "   ‚ùå EXCLUDED valuable 3D CT data\n",
      "   ‚ö†Ô∏è  REALITY CHECK: This is getting embarrassingly small\n",
      "\n",
      "üìÅ Updated output structure:\n",
      "   medmnist_multiversion/\n",
      "   ‚îú‚îÄ‚îÄ version_v1/Train_v1/ & Test_v1/ (10,000 images)\n",
      "   ‚îú‚îÄ‚îÄ version_v2/Train_v2/ & Test_v2/ (5,000 images)\n",
      "   ‚îú‚îÄ‚îÄ version_v3/Train_v3/ & Test_v3/ (2,500 images)\n",
      "   ‚îú‚îÄ‚îÄ version_v4/Train_v4/ & Test_v4/ (1,000 images)\n",
      "   ‚îî‚îÄ‚îÄ version_v5/Train_v5/ & Test_v5/ (1,000 images, NO 3D)\n",
      "   üö® TREND: Getting smaller AND less diverse = WRONG DIRECTION\n",
      "\n",
      "üéØ Version 5 created: 600 train + 150 test = 750 total\n",
      "‚ùå But you excluded valuable 3D data for no strategic reason\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import medmnist\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Updated dataset configurations\n",
    "DATASET_CONFIGS = {\n",
    "    'v1': {'train': 8000, 'test': 2000},\n",
    "    'v2': {'train': 4000, 'test': 1000}, \n",
    "    'v3': {'train': 2000, 'test': 500},\n",
    "    'v4': {'train': 800, 'test': 200},\n",
    "    'v5': {'train': 800, 'test': 200}  # Same size as v4 but NO 3D datasets\n",
    "}\n",
    "\n",
    "# EXCLUDED 3D datasets - this is what you're throwing away\n",
    "EXCLUDED_3D_DATASETS = ['organmnist3d', 'nodulemnist3d', 'fracturemnist3d', 'adrenalmnist3d']\n",
    "\n",
    "# Original percentages for reference\n",
    "ORIGINAL_PERCENTAGES = {\n",
    "    'chestmnist': 0.30,      # X-ray primary\n",
    "    'pneumoniamnist': 0.10,  # X-ray secondary\n",
    "    'organamnist': 0.10,     # CT axial\n",
    "    'organcmnist': 0.10,     # CT coronal\n",
    "    'organsmnist': 0.10,     # CT sagittal\n",
    "    'organmnist3d': 0.075,   # 3D CT primary - EXCLUDED\n",
    "    'nodulemnist3d': 0.075,  # 3D CT lung - EXCLUDED\n",
    "    'fracturemnist3d': 0.025,# 3D CT fracture - EXCLUDED\n",
    "    'adrenalmnist3d': 0.025, # 3D CT adrenal - EXCLUDED\n",
    "    'breastmnist': 0.10      # Ultrasound\n",
    "}\n",
    "\n",
    "# RECALCULATED percentages excluding 3D (total was 1.0, now 0.8, so we normalize)\n",
    "PERCENTAGES_V5 = {\n",
    "    'chestmnist': 0.375,     # 0.30/0.8 = increased from 30% to 37.5%\n",
    "    'pneumoniamnist': 0.125, # 0.10/0.8 = increased from 10% to 12.5%\n",
    "    'organamnist': 0.125,    # 0.10/0.8 = increased from 10% to 12.5%\n",
    "    'organcmnist': 0.125,    # 0.10/0.8 = increased from 10% to 12.5%\n",
    "    'organsmnist': 0.125,    # 0.10/0.8 = increased from 10% to 12.5%\n",
    "    'breastmnist': 0.125     # 0.10/0.8 = increased from 10% to 12.5%\n",
    "}\n",
    "\n",
    "DATASET_CLASS_MAPPING = {\n",
    "    'chestmnist': 'ChestMNIST',\n",
    "    'pneumoniamnist': 'PneumoniaMNIST',\n",
    "    'organamnist': 'OrganAMNIST',\n",
    "    'organcmnist': 'OrganCMNIST',\n",
    "    'organsmnist': 'OrganSMNIST',\n",
    "    'breastmnist': 'BreastMNIST'\n",
    "}\n",
    "\n",
    "def create_non_overlapping_splits(images, labels, train_count, test_count):\n",
    "    \"\"\"Create train/test splits with ZERO overlap\"\"\"\n",
    "    total_needed = train_count + test_count\n",
    "    \n",
    "    if len(images) < total_needed:\n",
    "        ratio = len(images) / total_needed\n",
    "        train_count = int(train_count * ratio)\n",
    "        test_count = int(test_count * ratio)\n",
    "        total_needed = train_count + test_count\n",
    "    \n",
    "    all_indices = np.arange(len(images))\n",
    "    np.random.shuffle(all_indices)\n",
    "    \n",
    "    train_indices = all_indices[:train_count]\n",
    "    test_indices = all_indices[train_count:train_count + test_count]\n",
    "    \n",
    "    train_images = images[train_indices]\n",
    "    train_labels = labels[train_indices]\n",
    "    test_images = images[test_indices] \n",
    "    test_labels = labels[test_indices]\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "def create_version_5_dataset(output_base='medmnist_multiversion', size=224):\n",
    "    \"\"\"\n",
    "    Create Version 5: NO 3D DATASETS - You're throwing away valuable data\n",
    "    800 train + 200 test = 1000 total images (embarrassingly small)\n",
    "    \"\"\"\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    \n",
    "    print(\"üîÑ PRE-LOADING NON-3D DATASETS FOR VERSION 5...\")\n",
    "    print(\"‚ö†Ô∏è  WARNING: You're EXCLUDING valuable 3D CT data for no good reason\")\n",
    "    \n",
    "    all_data = {}\n",
    "    \n",
    "    for dataset_name in PERCENTAGES_V5.keys():\n",
    "        print(f\"   Loading {dataset_name}...\")\n",
    "        try:\n",
    "            class_name = DATASET_CLASS_MAPPING[dataset_name]\n",
    "            dataset_class = getattr(medmnist, class_name)\n",
    "            \n",
    "            train_data = dataset_class(split='train', download=True, size=size)\n",
    "            val_data = dataset_class(split='val', download=True, size=size)\n",
    "            \n",
    "            combined_images = np.concatenate([train_data.imgs, val_data.imgs], axis=0)\n",
    "            combined_labels = np.concatenate([train_data.labels, val_data.labels], axis=0)\n",
    "            \n",
    "            all_data[dataset_name] = {\n",
    "                'images': combined_images,\n",
    "                'labels': combined_labels\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed to load {dataset_name}: {e}\")\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(all_data)} NON-3D datasets (threw away 4 valuable 3D datasets)\")\n",
    "    \n",
    "    # Create Version 5\n",
    "    version = 'v5'\n",
    "    config = DATASET_CONFIGS[version]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üéØ CREATING VERSION {version.upper()} (NO-3D MICRO-DATASET)\")\n",
    "    print(f\"üìä Train: {config['train']:,} | Test: {config['test']:,}\")\n",
    "    print(f\"‚ùå EXCLUDED: organmnist3d, nodulemnist3d, fracturemnist3d, adrenalmnist3d\")\n",
    "    print(f\"‚ö†Ô∏è  WARNING: You're making your dataset LESS diverse, not better\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    version_folder = os.path.join(output_base, f'version_{version}')\n",
    "    os.makedirs(version_folder, exist_ok=True)\n",
    "    \n",
    "    # Create train and test folders\n",
    "    train_folder = os.path.join(version_folder, f'Train_{version}')\n",
    "    test_folder = os.path.join(version_folder, f'Test_{version}')\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "    \n",
    "    train_total = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    # Process each remaining dataset according to NEW percentages\n",
    "    for dataset_name, percentage in PERCENTAGES_V5.items():\n",
    "        if dataset_name not in all_data:\n",
    "            continue\n",
    "            \n",
    "        train_target = int(config['train'] * percentage)\n",
    "        test_target = int(config['test'] * percentage)\n",
    "        \n",
    "        print(f\"\\nüìÇ {dataset_name}: {train_target} train, {test_target} test\")\n",
    "        \n",
    "        data = all_data[dataset_name]\n",
    "        \n",
    "        # Create non-overlapping splits\n",
    "        train_imgs, train_lbls, test_imgs, test_lbls = create_non_overlapping_splits(\n",
    "            data['images'], data['labels'], train_target, test_target\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úÖ Split: {len(train_imgs)} train, {len(test_imgs)} test\")\n",
    "        \n",
    "        # Save train images (only 2D data now)\n",
    "        for i, (img, label) in enumerate(zip(train_imgs, train_lbls)):\n",
    "            if len(img.shape) == 3 and img.shape[-1] == 1:\n",
    "                pil_img = Image.fromarray(img.squeeze(-1).astype(np.uint8), mode='L')\n",
    "            elif len(img.shape) == 3 and img.shape[-1] == 3:\n",
    "                pil_img = Image.fromarray(img.astype(np.uint8))\n",
    "            else:\n",
    "                pil_img = Image.fromarray(img.astype(np.uint8), mode='L')\n",
    "            \n",
    "            label_str = str(label[0]) if hasattr(label, '__len__') else str(label)\n",
    "            filename = f'{dataset_name}_{i:04d}_{label_str}.png'\n",
    "            filepath = os.path.join(train_folder, filename)\n",
    "            pil_img.save(filepath)\n",
    "        \n",
    "        # Save test images\n",
    "        for i, (img, label) in enumerate(zip(test_imgs, test_lbls)):\n",
    "            if len(img.shape) == 3 and img.shape[-1] == 1:\n",
    "                pil_img = Image.fromarray(img.squeeze(-1).astype(np.uint8), mode='L')\n",
    "            elif len(img.shape) == 3 and img.shape[-1] == 3:\n",
    "                pil_img = Image.fromarray(img.astype(np.uint8))\n",
    "            else:\n",
    "                pil_img = Image.fromarray(img.astype(np.uint8), mode='L')\n",
    "            \n",
    "            label_str = str(label[0]) if hasattr(label, '__len__') else str(label)\n",
    "            filename = f'{dataset_name}_{i:04d}_{label_str}.png'\n",
    "            filepath = os.path.join(test_folder, filename)\n",
    "            pil_img.save(filepath)\n",
    "        \n",
    "        train_total += len(train_imgs)\n",
    "        test_total += len(test_imgs)\n",
    "    \n",
    "    print(f\"\\n‚úÖ VERSION {version.upper()} COMPLETE:\")\n",
    "    print(f\"   üìà Train_{version}: {train_total:,} images\")\n",
    "    print(f\"   üß™ Test_{version}: {test_total:,} images\")\n",
    "    print(f\"   ‚ùå EXCLUDED valuable 3D CT data\")\n",
    "    print(f\"   ‚ö†Ô∏è  REALITY CHECK: This is getting embarrassingly small\")\n",
    "    \n",
    "    # Create version summary with brutal honesty\n",
    "    summary_path = os.path.join(version_folder, f'summary_{version}.txt')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(f\"DATASET VERSION {version.upper()} SUMMARY (NO 3D DATA)\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\")\n",
    "        f.write(f\"Train images: {train_total:,}\\n\")\n",
    "        f.write(f\"Test images: {test_total:,}\\n\")\n",
    "        f.write(f\"Total images: {train_total + test_total:,}\\n\")\n",
    "        f.write(f\"No overlap guarantee: YES\\n\")\n",
    "        f.write(f\"Modalities: X-ray (50%), 2D CT (37.5%), Ultrasound (12.5%)\\n\")\n",
    "        f.write(f\"EXCLUDED: All 3D CT datasets (20% of original data)\\n\")\n",
    "        f.write(f\"WARNING: Dataset too small AND less diverse\\n\")\n",
    "        f.write(f\"PROBLEM: You're optimizing in the wrong direction\\n\")\n",
    "    \n",
    "    print(f\"\\nüìÅ Updated output structure:\")\n",
    "    print(f\"   {output_base}/\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ version_v1/Train_v1/ & Test_v1/ (10,000 images)\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ version_v2/Train_v2/ & Test_v2/ (5,000 images)\") \n",
    "    print(f\"   ‚îú‚îÄ‚îÄ version_v3/Train_v3/ & Test_v3/ (2,500 images)\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ version_v4/Train_v4/ & Test_v4/ (1,000 images)\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ version_v5/Train_v5/ & Test_v5/ (1,000 images, NO 3D)\")\n",
    "    print(f\"   üö® TREND: Getting smaller AND less diverse = WRONG DIRECTION\")\n",
    "    \n",
    "    return train_total, test_total\n",
    "\n",
    "# EXECUTION\n",
    "if __name__ == \"__main__\":\n",
    "    train_count, test_count = create_version_5_dataset()\n",
    "    print(f\"\\nüéØ Version 5 created: {train_count} train + {test_count} test = {train_count + test_count} total\")\n",
    "    print(f\"‚ùå But you excluded valuable 3D data for no strategic reason\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
